"""CLI —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ RAG-—Å–∏—Å—Ç–µ–º—ã.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python run_comprehensive_benchmark.py --tier all --limit 50
    python run_comprehensive_benchmark.py --tier 1 --dataset golden_dataset_synthetic.json
"""

import argparse
import json
import logging
import os
import sys
from datetime import datetime
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from qa.config import Config
from qa.database import Chunk, create_engine
from benchmarks.models.rag_benchmark import RAGBenchmark
from benchmarks.utils.llm_judge import LLMJudge
from sentence_transformers import SentenceTransformer

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)

logger = logging.getLogger(__name__)


def check_prerequisites(engine, judge: LLMJudge, dataset_path: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤.

    Args:
        engine: –î–≤–∏–∂–æ–∫ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        judge: LLM-—Å—É–¥—å—è
        dataset_path: –ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É

    Returns:
        True –µ—Å–ª–∏ –≤—Å–µ —É—Å–ª–æ–≤–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω—ã
    """
    from sqlalchemy import select
    from sqlalchemy.orm import Session

    logger.info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π...")

    with Session(engine) as session:
        total_chunks = session.scalars(select(Chunk)).all()
        chunks_with_embeddings = [
            c for c in total_chunks if c.embedding is not None and len(c.embedding) > 0
        ]

        logger.info(f"–í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {len(total_chunks)}")
        logger.info(f"–ß–∞–Ω–∫–æ–≤ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏: {len(chunks_with_embeddings)}")

        if len(chunks_with_embeddings) == 0:
            logger.error(
                "‚ùå –ù–µ—Ç —á–∞–Ω–∫–æ–≤ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏! "
                "–ó–∞–ø—É—Å—Ç–∏—Ç–µ: python benchmarks/generate_embeddings.py --chunks"
            )
            return False

    if not os.path.exists(dataset_path):
        logger.error(
            f"‚ùå –î–∞—Ç–∞—Å–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {dataset_path}\n"
            "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç: python benchmarks/generate_dataset.py --num-samples 50"
        )
        return False

    logger.info("‚úÖ –í—Å–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω—ã")
    return True


def load_dataset(dataset_path: str, limit: Optional[int] = None) -> list:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ JSON —Ñ–∞–π–ª–∞.

    Args:
        dataset_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–∞—Ç–∞—Å–µ—Ç–∞
        limit: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π

    Returns:
        –°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π –¥–∞—Ç–∞—Å–µ—Ç–∞
    """
    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ {dataset_path}")

    with open(dataset_path, "r", encoding="utf-8") as f:
        dataset = json.load(f)

    if limit:
        dataset = dataset[:limit]

    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(dataset)} –∑–∞–ø–∏—Å–µ–π")

    return dataset


def run_benchmark(
    engine,
    encoder: SentenceTransformer,
    judge: LLMJudge,
    dataset: list,
    tier: str,
    top_k: int = 10,
):
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å –±–µ–Ω—á–º–∞—Ä–∫.

    Args:
        engine: –î–≤–∏–∂–æ–∫ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        encoder: –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        judge: LLM-—Å—É–¥—å—è
        dataset: –î–∞—Ç–∞—Å–µ—Ç
        tier: –£—Ä–æ–≤–µ–Ω—å –±–µ–Ω—á–º–∞—Ä–∫–∞ (1, 2, 3, all)
        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ (Tier 1)

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞
    """
    benchmark = RAGBenchmark(engine, encoder, judge)

    if tier == "all":
        return benchmark.run_all_tiers(dataset, top_k=top_k)
    elif tier == "1":
        return {"tier_1": benchmark.run_tier_1(dataset, top_k=top_k)}
    elif tier == "2":
        return {"tier_2": benchmark.run_tier_2(dataset)}
    elif tier == "3":
        return {"tier_3": benchmark.run_tier_3(dataset)}
    else:
        raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –±–µ–Ω—á–º–∞—Ä–∫–∞: {tier}")


def save_results(results: dict, output_dir: str):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞.

    Args:
        results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    os.makedirs(output_dir, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    json_path = os.path.join(output_dir, f"rag_benchmark_{timestamp}.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    markdown_path = os.path.join(output_dir, f"rag_benchmark_{timestamp}.md")
    with open(markdown_path, "w", encoding="utf-8") as f:
        f.write("# RAG Benchmark Report\n\n")
        f.write(f"**–í—Ä–µ–º—è:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

        for tier_name, tier_results in results.items():
            f.write(f"## {tier_name.upper()}\n\n")
            f.write("| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |\n")
            f.write("|---------|----------|\n")

            for key, value in tier_results.items():
                if key == "tier":
                    continue
                if isinstance(value, float):
                    f.write(f"| {key} | {value:.4f} |\n")
                else:
                    f.write(f"| {key} | {value} |\n")

            f.write("\n")

    logger.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
    logger.info(f"   JSON: {json_path}")
    logger.info(f"   Markdown: {markdown_path}")


def print_results(results: dict):
    """–í—ã–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞ –≤ –∫–æ–Ω—Å–æ–ª—å.

    Args:
        results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞
    """
    print("\n" + "=" * 60)
    print("RAG BENCHMARK RESULTS")
    print("=" * 60 + "\n")

    for tier_name, tier_results in results.items():
        print(f"üìä {tier_name.upper()}")
        print("-" * 60)

        for key, value in tier_results.items():
            if key == "tier":
                continue
            if isinstance(value, float):
                print(f"  {key}: {value:.4f}")
            else:
                print(f"  {key}: {value}")

        print()

    print("=" * 60 + "\n")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è CLI —Å–∫—Ä–∏–ø—Ç–∞."""
    parser = argparse.ArgumentParser(
        description="–ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ RAG-—Å–∏—Å—Ç–µ–º—ã"
    )

    parser.add_argument(
        "--tier",
        type=str,
        choices=["1", "2", "3", "all"],
        required=True,
        help="–£—Ä–æ–≤–µ–Ω—å –±–µ–Ω—á–º–∞—Ä–∫–∞ (1, 2, 3 –∏–ª–∏ all)",
    )

    parser.add_argument(
        "--dataset",
        type=str,
        default="benchmarks/data/golden_dataset_synthetic.json",
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–∞—Ç–∞—Å–µ—Ç–∞",
    )

    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞",
    )

    parser.add_argument(
        "--top-k",
        type=int,
        default=10,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ (Tier 1, default: 10)",
    )

    parser.add_argument(
        "--output-dir",
        type=str,
        default="benchmarks/reports",
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
    )

    parser.add_argument(
        "--skip-checks",
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π",
    )

    args = parser.parse_args()

    engine = create_engine(Config.SQLALCHEMY_DATABASE_URI)

    model_path = "nizamovtimur/multilingual-e5-large-wikiutmn"
    encoder = SentenceTransformer(model_path, device="cpu")

    judge = LLMJudge()

    if not args.skip_checks:
        if not check_prerequisites(engine, judge, args.dataset):
            sys.exit(1)

    dataset = load_dataset(args.dataset, args.limit)

    logger.info(f"–ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞ Tier {args.tier} —Å {len(dataset)} –∑–∞–ø–∏—Å—è–º–∏")

    results = run_benchmark(engine, encoder, judge, dataset, args.tier, args.top_k)

    save_results(results, args.output_dir)
    print_results(results)

    logger.info("‚úÖ –ë–µ–Ω—á–º–∞—Ä–∫ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à—ë–Ω")


if __name__ == "__main__":
    main()
