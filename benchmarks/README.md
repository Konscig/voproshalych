# –ú–æ–¥—É–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ RAG-—Å–∏—Å—Ç–µ–º—ã –í–æ–ø—Ä–æ—à–∞–ª—ã—á

Enterprise-grade —Å–∏—Å—Ç–µ–º–∞ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ Retrieval, Generation –∏ End-to-End
–∫–∞—á–µ—Å—Ç–≤–∞ RAG-–ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö PostgreSQL –∏ LLM-as-a-Judge.

## –û–±–∑–æ—Ä

–ú–æ–¥—É–ª—å `benchmarks` –ø–æ–∫—Ä—ã–≤–∞–µ—Ç —Ç—Ä–∏ —Ä–∞–±–æ—á–∏—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è:
- **Synthetic dataset**: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π golden standard.
- **Manual dataset**: —ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ –¥–ª—è —Å—Ç—Ä–æ–≥–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏.
- **Real user data**: retrieval-–º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.

### –ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- ‚úÖ **Single Source of Truth**: —Ä–∞–±–æ—Ç–∞ —Å —Ä–µ–∞–ª—å–Ω–æ–π PostgreSQL –±–∞–∑–æ–π
- ‚úÖ **LLM-as-a-Judge**: –æ—Ü–µ–Ω–∫–∞ quality-–º–µ—Ç—Ä–∏–∫ —á–µ—Ä–µ–∑ judge-model
- ‚úÖ **–¢—Ä–∏ tier-—É—Ä–æ–≤–Ω—è**: Retrieval, Generation, End-to-End
- ‚úÖ **Manual + Real Users —Ä–µ–∂–∏–º—ã**: –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–∞–π–ø–ª–∞–π–Ω—ã –¥–ª—è –∞–∫–∞–¥–µ–º–∏—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
- ‚úÖ **–í–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã**: JSON/Markdown –æ—Ç—á—ë—Ç—ã + `benchmark_runs`

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
benchmarks/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ dataset_YYYYMMDD_HHMMSS.json
‚îÇ   ‚îú‚îÄ‚îÄ manual_dataset_YYYYMMDD_HHMMSS.json
‚îÇ   ‚îî‚îÄ‚îÄ dataset_errors_YYYYMMDD_HHMMSS.json
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ manual_annotation_guide.md
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ rag_benchmark.py
‚îÇ   ‚îî‚îÄ‚îÄ real_queries_benchmark.py
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ rag_benchmark_*.json
‚îÇ   ‚îî‚îÄ‚îÄ rag_benchmark_*.md
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ llm_judge.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluator.py
‚îÇ   ‚îî‚îÄ‚îÄ embedding_generator.py
‚îú‚îÄ‚îÄ Makefile
‚îú‚îÄ‚îÄ dashboard.py
‚îú‚îÄ‚îÄ generate_embeddings.py
‚îú‚îÄ‚îÄ generate_dataset.py
‚îú‚îÄ‚îÄ load_database_dump.py
‚îú‚îÄ‚îÄ run_comprehensive_benchmark.py
‚îî‚îÄ‚îÄ run_dashboard.py
```
 
## Smoke-—Å—Ü–µ–Ω–∞—Ä–∏–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

–î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ –¥–æ—Å—Ç—É–ø–Ω—ã –¥–≤–∞ Smoke-—Å—Ü–µ–Ω–∞—Ä–∏—è:

### –õ–æ–∫–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

–ü–æ–ª–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –±–µ–∑ Docker:
- üìÑ [SMOKE_SCENARIO_LOCAL.md](SMOKE_SCENARIO_LOCAL.md) - –ª–æ–∫–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å `uv run`
- –¢—Ä–µ–±—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ PostgreSQL –∏ Python 3.12+
- –í—Å–µ –∫–æ–º–∞–Ω–¥—ã –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ —á–µ—Ä–µ–∑ UV

### –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è —Å Docker

–ü–æ–ª–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ Docker –æ–∫—Ä—É–∂–µ–Ω–∏–∏:
- üìÑ [SMOKE_SCENARIO_DOCKER.md](SMOKE_SCENARIO_DOCKER.md) - —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å `docker-compose.benchmarks.yml`
- –ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–µ–∫ —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ volumes –¥–ª—è –∫—ç—à–∞, –æ—Ç—á—ë—Ç–æ–≤ –∏ –¥–∞–Ω–Ω—ã—Ö
- –í—Å–µ –∫–æ–º–∞–Ω–¥—ã –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤

### –í—ã–±–æ—Ä —Å—Ü–µ–Ω–∞—Ä–∏—è

| –°—Ü–µ–Ω–∞—Ä–∏–π | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å | –û–∫—Ä—É–∂–µ–Ω–∏–µ |
|-----------|-------------------|-------------|
| LOCAL | –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞, –æ—Ç–ª–∞–¥–∫–∞, –±—ã—Å—Ç—Ä—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ | –õ–æ–∫–∞–ª—å–Ω—ã–π Python + PostgreSQL |
| DOCKER | CI/CD, –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, –ø—Ä–æ–¥–∞–∫—à–Ω | Docker + Docker Compose |

## –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã

### 1) LLM-—Å—É–¥—å—è (`utils/llm_judge.py`)

- `generate_question_from_chunk()` ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–∞ –∏ ground truth –æ—Ç–≤–µ—Ç–∞
- `evaluate_faithfulness()` ‚Äî –æ—Ü–µ–Ω–∫–∞ —Ñ–∞–∫—Ç–∏—á–Ω–æ—Å—Ç–∏ (1..5)
- `evaluate_answer_relevance()` ‚Äî –æ—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (1..5)
- `evaluate_e2e_quality()` ‚Äî –∏—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞ (1..5)

### 2) –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (`generate_embeddings.py`)

–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è `QuestionAnswer` –∏ `Chunk`.

### 3) –ì–µ–Ω–µ—Ä–∞—Ü–∏—è synthetic dataset (`generate_dataset.py`)

–ù–æ–≤–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:
- –ø–æ–ø—ã—Ç–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è **–∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞** —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–º –∏ –Ω–µ–ø—É—Å—Ç—ã–º —Ç–µ–∫—Å—Ç–æ–º;
- —Å—Ç—Ä–∞—Ç–µ–≥–∏—è **1 —á–∞–Ω–∫ -> 1 –≤–æ–ø—Ä–æ—Å** –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è `--max-questions`;
- retry –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–∫—Ä–∏–ø—Ç–∞ + retry –≤ `LLMJudge`;
- –æ—Ç–¥–µ–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç `dataset_errors_*.json` —Å –ø—Ä–∏—á–∏–Ω–∞–º–∏ –æ—à–∏–±–æ–∫;
- –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è —á–µ—Ä–µ–∑ `--skip-existing-dataset`.

### 4) –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π —Ä–∞–Ω–Ω–µ—Ä (`run_comprehensive_benchmark.py`)

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ä–µ–∂–∏–º—ã:
- `--mode synthetic` (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
- `--mode manual`
- `--mode real-users`

## –¢—Ä–∏ —É—Ä–æ–≤–Ω—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

### Tier 1: Retrieval Accuracy

**–ü—Ä–æ—Ü–µ–¥—É—Ä–∞:**
1. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞.
2. –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è vector search –ø–æ `Chunk.embedding.cosine_distance(...)`.
3. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è hit-rate –∏ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ IR-–º–µ—Ç—Ä–∏–∫–∏.

–í –∫–æ–¥–µ: `benchmarks/models/rag_benchmark.py`, `benchmarks/utils/evaluator.py`.

**–ú–µ—Ç—Ä–∏–∫–∏:** `HitRate@K`, `Recall@K`, `Precision@K`, `MRR`, `NDCG@K`.

$$
\mathrm{HitRate@K} = \frac{1}{|Q|} \sum_{q \in Q} \mathbf{1}[\exists d \in \mathrm{TopK}(q): d \in G_q]
$$

$$
\mathrm{Recall@K} = \frac{1}{|Q|} \sum_{q \in Q} \frac{|\mathrm{TopK}(q) \cap G_q|}{|G_q|}
$$

$$
\mathrm{Precision@K} = \frac{1}{|Q|} \sum_{q \in Q} \frac{|\mathrm{TopK}(q) \cap G_q|}{K}
$$

$$
\mathrm{MRR} = \frac{1}{|Q|} \sum_{q \in Q} \frac{1}{\mathrm{rank}_q}
$$

$$
\mathrm{NDCG@K} = \frac{1}{|Q|} \sum_{q \in Q} \frac{\mathrm{DCG@K}(q)}{\mathrm{IDCG@K}(q)}
$$

### Tier 2: Generation Quality

**–ü—Ä–æ—Ü–µ–¥—É—Ä–∞:**
1. –î–ª—è –≤–æ–ø—Ä–æ—Å–∞ —Å–æ–±–∏—Ä–∞–µ—Ç—Å—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–ø–æ `chunk_text`,
   `relevant_chunk_ids`, `chunk_id` –∏–ª–∏ `relevant_urls`).
2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ —Ä–µ–∞–ª—å–Ω—ã–π pipeline `qa.main.get_answer`.
3. LLM Judge –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ñ–∞–∫—Ç–∏—á–Ω–æ—Å—Ç—å –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å.

**–ú–µ—Ç—Ä–∏–∫–∏:** `avg_faithfulness`, `avg_answer_relevance`.

$$
\mathrm{avg\_faithfulness} = \frac{1}{N} \sum_{i=1}^{N} s_i,
\quad s_i \in \{1,2,3,4,5\}
$$

$$
\mathrm{avg\_answer\_relevance} = \frac{1}{N} \sum_{i=1}^{N} s_i,
\quad s_i \in \{1,2,3,4,5\}
$$

–®–∫–∞–ª–∞ 1..5 —Ç—Ä–∞–∫—Ç—É–µ—Ç—Å—è –∫–∞–∫ **ordinal scale** (—É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–∞—è, –Ω–µ —Å—Ç—Ä–æ–≥–æ –ª–∏–Ω–µ–π–Ω–∞—è).

### Tier 3: End-to-End

**–ü—Ä–æ—Ü–µ–¥—É—Ä–∞:**
1. –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è retrieval top-1 –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞.
2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ retrieved –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.
3. Judge –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç `E2E score` –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ `ground_truth_answer`.
4. –°—á–∏—Ç–∞–µ—Ç—Å—è –∫–æ—Å–∏–Ω—É—Å–Ω–∞—è –±–ª–∏–∑–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∏ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.

**–ú–µ—Ç—Ä–∏–∫–∏:** `avg_e2e_score`, `avg_semantic_similarity`.

$$
\mathrm{avg\_e2e\_score} = \frac{1}{N} \sum_{i=1}^{N} s_i,
\quad s_i \in \{1,2,3,4,5\}
$$

$$
\mathrm{cos\_sim}(u, v) = \frac{u \cdot v}{\|u\|\,\|v\|}
$$

## CLI –∫–æ–º–∞–Ω–¥—ã

### `load_database_dump.py`

```bash
uv run python benchmarks/load_database_dump.py --dump benchmarks/data/dump/virtassist_backup_20260213.dump
uv run python benchmarks/load_database_dump.py --dump-dir benchmarks/data/dump
uv run python benchmarks/load_database_dump.py --drop-tables-only
```

**–í–∞–∂–Ω–æ:** –ü—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–º–ø–∞ —Ç–∞–±–ª–∏—Ü—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—á–∏—â–∞—é—Ç—Å—è –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π. –§–ª–∞–≥ `--drop-tables-only` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü –±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–º–ø–∞.

### `generate_embeddings.py`

```bash
docker compose -f docker-compose.benchmarks.yml exec benchmarks uv run python benchmarks/generate_embeddings.py --chunks
docker compose -f docker-compose.benchmarks.yml exec benchmarks uv run python benchmarks/generate_embeddings.py --all
docker compose -f docker-compose.benchmarks.yml exec benchmarks uv run python benchmarks/generate_embeddings.py --score 5
docker compose -f docker-compose.benchmarks.yml exec benchmarks uv run python benchmarks/generate_embeddings.py --check-coverage
```

### `generate_dataset.py`

```bash
docker compose -f docker-compose.benchmarks.yml exec benchmarks uv run python benchmarks/generate_dataset.py --max-questions 500
docker compose -f docker-compose.benchmarks.yml exec benchmarks uv run python benchmarks/generate_dataset.py --max-questions 300 --output benchmarks/data/dataset_custom.json
docker compose -f docker-compose.benchmarks.yml exec benchmarks uv run python benchmarks/generate_dataset.py --max-questions 500 --skip-existing-dataset benchmarks/data/dataset_20260216_124845.json
docker compose -f docker-compose.benchmarks.yml exec benchmarks uv run python benchmarks/generate_dataset.py --check-only --output benchmarks/data/dataset_custom.json
```

### `run_comprehensive_benchmark.py`

```bash
docker compose -f docker-compose.benchmarks.yml exec benchmarks uv run python benchmarks/run_comprehensive_benchmark.py --tier all --mode synthetic --dataset benchmarks/data/dataset_20260216_124845.json
docker compose -f docker-compose.benchmarks.yml exec benchmarks uv run python benchmarks/run_comprehensive_benchmark.py --tier all --mode manual --manual-dataset benchmarks/data/manual_dataset_20260217_101500.json
docker compose -f docker-compose.benchmarks.yml exec benchmarks uv run python benchmarks/run_comprehensive_benchmark.py --mode real-users --real-score 5 --real-limit 500 --top-k 10
```

### `run_dashboard.py`

```bash
docker compose -f docker-compose.benchmarks.yml run --rm -p 7860:7860 benchmarks uv run python benchmarks/run_dashboard.py
```

## –ó–∞–ø—É—Å–∫ —Å docker-compose.benchmarks.yml

–î–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–µ–Ω—á–º–∞—Ä–∫–∞–º–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω—ã–π docker-compose —Ñ–∞–π–ª `docker-compose.benchmarks.yml`.

### –û–ø–∏—Å–∞–Ω–∏–µ

–≠—Ç–æ—Ç —Ñ–∞–π–ª –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è:
- –í—Å–µ —Å–µ—Ä–≤–∏—Å—ã –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (db, db-migrate, qa, chatbot, adminpanel, max)
- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å `benchmarks` —Å –ø–æ—Ä—Ç–æ–º 7860 –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞
- –û—Ç–¥–µ–ª—å–Ω—ã–µ volumes –¥–ª—è reports, data –∏ cache –±–µ–Ω—á–º–∞—Ä–∫–æ–≤

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞

- **–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–µ–∫**: –ü–æ–ª–Ω–∞—è —Å—Ä–µ–¥–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–µ–Ω—á–º–∞—Ä–∫–æ–≤
- **–û—Ç–¥–µ–ª—å–Ω—ã–µ volumes**: –î–∞–Ω–Ω—ã–µ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ —Ö—Ä–∞–Ω—è—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ –æ—Ç –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
- **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏**: –°–µ—Ä–≤–∏—Å benchmarks –∏—Å–ø–æ–ª—å–∑—É–µ—Ç UV –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏
- **–ï–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞ –∑–∞–ø—É—Å–∫–∞**: –í—Å–µ —Å–µ—Ä–≤–∏—Å—ã –ø–æ–¥–Ω–∏–º–∞—é—Ç—Å—è –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π

### –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

```bash
# –ü–æ–¥–Ω—è—Ç—å —Å—Ç–µ–∫ —Å –±–µ–Ω—á–º–∞—Ä–∫–∞–º–∏
cd Submodules/voproshalych
docker compose -f docker-compose.benchmarks.yml up -d --build

# –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å
docker compose -f docker-compose.benchmarks.yml down
```

üëâ **–ü–æ–¥—Ä–æ–±–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏**: [SMOKE_SCENARIO_DOCKER.md](SMOKE_SCENARIO_DOCKER.md)

## –ë—ã—Å—Ç—Ä—ã–µ —à–æ—Ä—Ç–∫–∞—Ç—ã (docker compose)

–ò–∑ `Submodules/voproshalych` —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º `docker-compose.benchmarks.yml`:

```bash
uv run python benchmarks/load_database_dump.py --dump benchmarks/data/dump/virtassist_backup_20260213.dump
docker compose -f docker-compose.benchmarks.yml exec benchmarks uv run python benchmarks/generate_embeddings.py --chunks
docker compose -f docker-compose.benchmarks.yml exec benchmarks uv run python benchmarks/generate_dataset.py --max-questions 500
docker compose -f docker-compose.benchmarks.yml exec benchmarks uv run python benchmarks/run_comprehensive_benchmark.py --tier all --mode synthetic
docker compose -f docker-compose.benchmarks.yml run --rm -p 7860:7860 benchmarks uv run python benchmarks/run_dashboard.py
```

### –ß–µ—Ä–µ–∑ Makefile

```bash
cd Submodules/voproshalych/benchmarks
make install
make load-dump
make generate-embeddings
make generate-dataset
make run-benchmarks
make run-dashboard
make help
```

–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã Makefile:
- `up` - –ø–æ–¥–Ω—è—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–µ–∫
- `down` - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç–µ–∫
- `up-benchmarks` - –ø–æ–¥–Ω—è—Ç—å —Å—Ç–µ–∫ —Å –±–µ–Ω—á–º–∞—Ä–∫–∞–º–∏
- `down-benchmarks` - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—Ç–µ–∫ —Å –±–µ–Ω—á–º–∞—Ä–∫–∞–º–∏
- `ps` - –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–æ–≤
- `logs` - –ø–æ–∫–∞–∑–∞—Ç—å –ª–æ–≥–∏ —Å–µ—Ä–≤–∏—Å–∞ benchmarks

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```mermaid
sequenceDiagram
    participant User
    participant Benchmarks as benchmarks CLI/dashboard
    participant QAService as qa.get_answer
    participant Postgres as PostgreSQL
    participant JudgeLLM as LLMJudge

    User->>Benchmarks: run_comprehensive_benchmark.py (tier=all, mode=synthetic/manual)
    Benchmarks->>Postgres: SELECT Chunk / BenchmarkRun / QuestionAnswer
    Benchmarks->>QAService: get_answer(question, context)
    QAService->>Postgres: vector retrieval (cosine_distance)
    QAService-->>Benchmarks: generated answer + retrieved chunks
    Benchmarks->>JudgeLLM: faithfulness/relevance/e2e evaluation
    JudgeLLM-->>Benchmarks: scores 1..5
    Benchmarks->>Postgres: INSERT INTO benchmark_runs
    User->>Benchmarks: run_dashboard.py
    Benchmarks->>Postgres: SELECT benchmark_runs
    Benchmarks-->>User: interactive metrics dashboard
    ```

## –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- `benchmarks/docs/manual_annotation_guide.md`
- `benchmarks/dashboard.py`
- `benchmarks/run_comprehensive_benchmark.py`
