[project]
name = "voproshalych-benchmarks"
version = "0.1.0"
description = "Benchmarking system for RAG evaluation"
readme = "README.md"
requires-python = ">=3.12"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project.dependencies]
python-dotenv = "*"
sqlalchemy = "*"
psycopg2-binary = "*"
pgvector = "*"
sentence-transformers = "*"
numpy = "*"

[project.optional-dependencies]
llm-judge = [
    "openai>=1.0.0",
]

dashboard = [
    "gradio>=6.5.1",
]

all = [
    "voproshalych-benchmarks[llm-judge,dashboard]",
]

[tool.black]
line-length = 88
target-version = ['py312']

[tool.isort]
profile = "black"
line_length = 88
