# Комплексный научно-технический отчёт по результатам бенчмаркинга RAG-системы «Вопрошалыч»

**Дата проведения исследования:** 23 февраля 2026 года  
**Версия системы:** Git-коммит `488332f`, ветка `feat/benchmark-rag-quality`  
**Автор запуска:** webmasha  
**Датасет:** `dataset_synthetic_20260223_183530.json` (synthetic mode)  
**Общее количество запросов в бенчмарке:** 202  

---

## Аннотация

Настоящий документ представляет собой комплексный научно-технический отчёт по результатам всестороннего бенчмаркинга системы «Вопрошалыч» — интеллектуального чат-бота для поддержки студентов Тюменского государственного университета, реализованного на основе архитектуры Retrieval-Augmented Generation (RAG). Исследование проведено с использованием многоуровневой методологии оценки, охватывающей три ключевых компонента системы: слой извлечения релевантной информации (retrieval layer), слой генерации ответов (generation layer) и сквозное качество системы (end-to-end quality). Дополнительно выполнен анализ характеристик векторного пространства эмбеддингов, покрытия тематических кластеров, утилизации чанков базы знаний и предметной области реальных пользовательских запросов.

Результаты исследования свидетельствуют о наличии ряда существенных проблем в функционировании системы, требующих незамедлительного внимания и оптимизации. Общий статус системы определён как **критический** (critical) на основании сравнительного анализа полученных метрик с целевыми baseline-значениями.

---

## 1. Введение

### 1.1. Предмет и цели исследования

Система «Вопрошалыч» представляет собой интеллектуального помошника на базе RAG-архитектуры, предназначенного для оказания информационной поддержки студентам Тюменского государственного университета. Система использует комбинированный подход, объединяющий семантический поиск по векторной базе знаний с генеративной моделью Large Language Model (LLM) для формирования итоговых ответов на естественном языке.

Целью настоящего исследования является всесторонняя количественная и качественная оценка производительности системы по трём ключевым измерениям: эффективность извлечения релевантных документов, качество сгенерированных ответов и интегральная оценка пользовательского опыта. Помимо этого, исследование направлено на выявление системных проблем, определение их причин и формулирование рекомендаций по улучшению.

### 1.2. Методологическая база

Оценка системы проводилась с использованием многоуровневой методологии бенчмаркинга, включающей следующие компоненты:

- **Tier 0 (Intrinsic Embedding Quality):** анализ внутренних характеристик векторных представлений без использования внешних меток;
- **Tier 1 (Retrieval Quality):** оценка качества работы поискового модуля по стандартным метрикам информационного поиска;
- **Tier 2 (Generation Quality):** оценка качества сгенерированных ответов по параметрам фактической точности, релевантности и семантической согласованности;
- **Tier 3 (End-to-End Quality):** интегральная оценка итогового пользовательского опыта от момента формирования запроса до получения ответа;
- **Дополнительные аналитики:** утилизация чанков, покрытие тематических кластеров, анализ предметной области реальных запросов.

---

## 2. Анализ качества извлечения информации (Tier 1)

### 2.1. Методологический контекст

Слой извлечения информации (retrieval layer) является фундаментальным компонентом любой RAG-системы, определяющим качество всего последующего конвейера обработки запросов. Эффективность данного слоя напрямую влияет на релевантность контекста, передаваемого генеративной модели, и, следовательно, на качество итоговых ответов. В рамках настоящего исследования качество извлечения оценивалось по широкому спектру метрик информационного поиска, включая Hit Rate, Mean Reciprocal Rank (MRR), Recall, Precision и Normalized Discounted Cumulative Gain (NDCG).

### 2.2. Результаты эмпирической оценки

Результаты тестирования retrieval-слоя представлены в таблице 1.

**Таблица 1. Метрики качества извлечения информации (Tier 1)**

| Метрика | Полученное значение | Baseline | Отклонение от baseline | Статус |
|---------|---------------------|----------|------------------------|--------|
| Hit Rate @ 1 | 0.3465 (34.65%) | 0.70 | -50.36% | below_target |
| Hit Rate @ 5 | 0.6634 (66.34%) | 0.90 | -26.29% | below_target |
| Hit Rate @ 10 | 0.7871 (78.71%) | 0.95 | -17.15% | below_target |
| MRR | 0.5945 | 0.80 | -25.69% | below_target |
| Retrieval Consistency | 1.0000 | 0.95 | +5.26% | ok |
| Recall @ 1 | 0.4307 (43.07%) | — | — | n/a |
| Recall @ 3 | 0.7079 (70.79%) | — | — | n/a |
| Recall @ 5 | 0.8317 (83.17%) | — | — | n/a |
| Recall @ 10 | 0.9307 (93.07%) | — | — | n/a |
| Precision @ 1 | 0.4307 (43.07%) | — | — | n/a |
| Precision @ 3 | 0.2360 (23.60%) | — | — | n/a |
| Precision @ 5 | 0.1663 (16.63%) | — | — | n/a |
| Precision @ 10 | 0.0931 (9.31%) | — | — | n/a |
| NDCG @ 5 | 0.8681 | — | — | n/a |
| NDCG @ 10 | 1.0923 | — | — | n/a |

### 2.3. Интерпретация результатов

#### 2.3.1. Анализ показателя Hit Rate

Показатель Hit Rate, определяющий долю запросов, для которых хотя бы один релевантный документ присутствует в top-k результатах поиска, демонстрирует неудовлетворительные результаты по всем трём значениям параметра k. При k=1 система способна корректно ранжировать наиболее релевантный документ на первой позиции лишь в **34.65% случаев**, что существенно ниже целевого значения в 70%. Данный показатель свидетельствует о серьёзных проблемах с пертинентностью ранжирования — алгоритм поиска нередко помещает релевантные документы на позиции, недоступные пользователю без прокрутки результатов.

При расширении окна до top-5 Hit Rate возрастает до 66.34%, однако это всё ещё на 26.29% ниже целевого baseline в 90%. При top-10 показатель достигает 78.71%, что указывает на то, что релевантные документы в большинстве случаев (более 4/5) присутствуют в расширенном наборе результатов, однако требуют от пользователя просмотра значительного количества нерелевантных документов.

#### 2.3.2. Анализ Mean Reciprocal Rank (MRR)

Показатель Mean Reciprocal Rank, представляющий собой усреднённую обратную позицию первого релевантного документа, составил **0.5945** при целевом значении 0.80. Это означает, что в среднем первый релевантный документ обнаруживается на позиции примерно 1.68 (1/0.5945), что свидетельствует о необходимости существенной оптимизации алгоритма ранжирования.

Снижение MRR на 25.69% относительно baseline указывает на систематические проблемы с релевантностью, которые не могут быть объяснены случайными флуктуациями. Вероятными причинами являются: неоптимальные параметры модели эмбеддингов, недостаточная релевантность текстовых чанков в базе знаний, некорректная обработка синонимов и морфологических вариаций русскоязычных запросов.

#### 2.3.3. Анализ Recall и Precision

Показатели полноты извлечения (Recall) демонстрируют положительную динамику: при k=10 система охватывает 93.07% релевантных документов, что свидетельствует о высокой полноте поиска. Однако показатели точности (Precision) существенно снижаются при увеличении k: при k=1 точность составляет 43.07%, тогда как при k=10 она падает до 9.31%. Это указывает на то, что в результатах поиска присутствует значительное количество нерелевантных документов, особенно в расширенных позициях.

#### 2.3.4. Анализ NDCG

Нормализованный дисконтированный кумулятивный выигрыш (NDCG) является метрикой, учитывающей как наличие релевантных документов в результатах, так и их позиции. Значение NDCG@5 = 0.8681 и NDCG@10 = 1.0923 указывает на то, что релевантные документы, хотя и присутствуют в результатах, нередко располагаются на неоптимальных позициях. Показатель NDCG@10, превышающий 1.0, объясняется особенностями нормализации в условиях ограниченного размера релевантного набора.

### 2.4. Выводы по Tier 1

Качество извлечения информации в системе «Вопрошалыч» характеризуется как **неудовлетворительное** по критериям, принятым в рамках данного исследования. Ключевые проблемы включают:

1. **Низкая пертинентность top-1 ранжирования:** лишь 34.65% запросов получают релевантный документ на первой позиции;
2. **Недостаточная конкурентоспособность относительно baseline:** все основные метрики демонстрируют отклонение на 17-50% от целевых значений;
3. **Высокая полнота при низкой точности:** при k=10 Recall достигает 93.07%, однако Precision составляет лишь 9.31%, что указывает на перегруженность результатов нерелевантными документами.

Рекомендуется провести комплексную оптимизацию retrieval-слоя, включая: пересмотр модели эмбеддингов, внедрение гибридного поиска (векторный + BM25), оптимизацию процедуры разбиения документов на чанки (chunking), а также калибровку параметров косинусного сходства.

---

## 3. Анализ качества генерации (Tier 2)

### 3.1. Методологический контекст

Второй уровень оценки (Tier 2) направлен на анализ качества ответов, генерируемых Large Language Model на основе извлечённого контекста. Данный уровень критически важен, поскольку даже безупречная работа retrieval-слоя не гарантирует качественного пользовательского опыта при неэффективной генерации. Оценка проводилась по трём ключевым измерениям: Faithfulness (соответствие фактам из контекста), Answer Relevance (релевантность вопросу) и Answer Correctness (корректность относительно эталонного ответа).

### 3.2. Результаты эмпирической оценки

**Таблица 2. Метрики качества генерации (Tier 2)**

| Метрика | Полученное значение | Baseline | Отклонение от baseline | Статус |
|---------|---------------------|----------|------------------------|--------|
| Total Queries | 202 | — | — | n/a |
| Successful Evaluations | 198 (98.02%) | — | — | n/a |
| Errors | 4 (1.98%) | — | — | n/a |
| Avg Faithfulness | 3.4394 | 4.50 | -23.57% | below_target |
| Avg Answer Relevance | 3.5354 | 4.20 | -15.82% | below_target |
| Avg Answer Correctness | 2.9545 | 4.20 | -29.65% | below_target |
| Response Exact Match Rate | 0.1717 (17.17%) | 0.70 | -75.47% | below_target |
| Response Semantic Consistency | 0.8486 | 0.85 | -0.16% | below_target |
| Avg ROUGE-1 F | 0.1471 | — | — | n/a |
| Avg ROUGE-2 F | 0.0916 | — | — | n/a |
| Avg ROUGE-L F | 0.1461 | — | — | n/a |
| Avg BLEU | 9.1331 | — | — | n/a |

### 3.3. Интерпретация результатов

#### 3.3.1. Анализ Faithfulness

Средний показатель Faithfulness составил **3.4394 из 5.0** при целевом значении 4.50, что соответствует отклонению на 23.57%. Данная метрика оценивает степень соответствия сгенерированного ответа фактам, содержащимся в извлечённом контексте, иначе говоря — отсутствие галлюцинаций. Показатель 3.44 указывает на то, что в среднем ответы характеризуются как «частично соответствующие контексту с некоторыми неточностями».

Снижение Faithfulness относительно baseline может быть обусловлено несколькими факторами: (а) недостаточной инструкцией в system prompt, (б) неоптимальной температурой генерации, (в) ограниченным объёмом контекста, передаваемого модели, (г) особенностями архитектуры самой LLM (модель `open-mistral-nemo`). Вероятно, имеет место комбинация указанных факторов.

#### 3.3.2. Анализ Answer Relevance

Средняя релевантность ответов составила **3.5354 из 5.0** при baseline 4.20 (отклонение -15.82%). Данная метрика оценивает, насколько генерируемый ответ соответствует исходному запросу пользователя по существу. Значение 3.54 указывает на «частичное соответствие вопросу» — ответы в целом направлены на решение поставленного вопроса, однако содержат неточности или отклонения от основной темы.

Снижение Answer Relevance может быть связано с: неоптимальной формулировкой system prompt, недостаточным учётом контекста диалога, а также проблемами с извлечением релевантного контекста на Tier 1.

#### 3.3.3. Анализ Answer Correctness

Наиболее критичным является показатель Answer Correctness, составивший лишь **2.9545 из 5.0** при целевом значении 4.20 (отклонение -29.65%). Это наименьшее значение среди всех метрик Tier 2, что свидетельствует о серьёзных проблемах с точностью ответов относительно эталонных решений.

Показатель 2.95 интерпретируется как «значимые пробелы и существенные неточности» в ответах. Это может быть обусловлено: (а) низким качеством контекста, передаваемого от retrieval-слоя, (б) несоответствием между эталонными ответами в датасете и фактическими ожиданиями пользователей, (в) архитектурными ограничениями генеративной модели.

#### 3.3.4. Анализ Response Exact Match Rate

Показатель точного совпадения с эталонными ответами составил лишь **17.17%** при baseline 70% — отклонение на 75.47%. Данный показатель отражает долю ответов, которые полностью совпадают с эталонными ответами из датасета. Столь низкое значение, однако, не обязательно свидетельствует о плохом качестве системы: оно может объясняться вариативностью формулировок при идентичном содержании.

#### 3.3.5. Анализ семантической согласованности

Показатель Response Semantic Consistency составил **0.8486** при baseline 0.85 — практически полное соответствие целевому значению (отклонение -0.16%). Данная метрика оценивает стабильность ответов при повторных генерациях на идентичные запросы. Высокое значение указывает на детерминированность работы генеративной модели и воспроизводимость результатов.

#### 3.3.6. Анализ текстовых метрик (ROUGE, BLEU)

Метрики ROUGE и BLEU, основанные на сравнении n-грамм между сгенерированными и эталонными ответами, демонстрируют ожидаемо низкие значения: ROUGE-1 F = 0.1471, ROUGE-2 F = 0.0916, ROUGE-L F = 0.1461, BLEU = 9.13. Данные значения типичны для задач с высокой вариативностью формулировок и не могут рассматриваться как индикаторы критических проблем.

### 3.4. Выводы по Tier 2

Качество генерации в системе характеризуется как **неудовлетворительное**, с наиболее критичными проблемами в области фактической точности (Answer Correctness):

1. **Высокий уровень галлюцинаций:** Faithfulness 3.44 указывает на частое искажение фактов из контекста;
2. **Низкая корректность ответов:** Answer Correctness 2.95 свидетельствует о значимых расхождениях с эталонными решениями;
3. **Существенное отклонение от baseline по всем ключевым метрикам:** 15-30% ниже целевых значений;
4. **Низкая точность совпадения:** Exact Match Rate 17.17% требует анализа причин.

Рекомендуется: оптимизация system prompt с акцентом на фактическую точность, калибровка параметра temperature, расширение контекстного окна, рассмотрение возможности перехода на более производительную генеративную модель.

---

## 4. Анализ сквозного качества (Tier 3)

### 4.1. Методологический контекст

Третий уровень оценки (Tier 3) представляет собой интегральную оценку сквозного пользовательского опыта — от момента формирования запроса до получения итогового ответа. В отличие от Tier 1 и Tier 2, данный уровень оценивает систему как единое целое, без декомпозиции на компоненты, что позволяет получить наиболее релевантную картину реального пользовательского опыта.

### 4.2. Результаты эмпирической оценки

**Таблица 3. Метрики сквозного качества (Tier 3)**

| Метрика | Полученное значение | Baseline | Отклонение от baseline | Статус |
|---------|---------------------|----------|------------------------|--------|
| Total Queries | 202 | — | — | n/a |
| Successful Evaluations | 201 (99.50%) | — | — | n/a |
| Errors | 1 (0.50%) | — | — | n/a |
| Avg E2E Score | 2.5025 | 4.20 | -40.42% | below_target |
| Avg Semantic Similarity | 0.5382 | 0.85 | -36.68% | below_target |
| Avg Dot Similarity | 0.5382 | — | — | n/a |
| Avg Euclidean Distance | 0.9257 | — | — | n/a |
| Response Exact Match Rate | 0.1294 (12.94%) | 0.70 | -81.51% | below_target |
| Response Semantic Consistency | 0.8705 | 0.85 | +2.41% | ok |

### 4.3. Интерпретация результатов

#### 4.3.1. Анализ E2E Score

Средний сквозной балл составил **2.5025 из 5.0** при целевом значении 4.20 — отклонение на 40.42%. Это **наиболее критичный показатель** среди всех метрик исследования, свидетельствующий о серьёзных системных проблемах в контуре пользовательского взаимодействия.

Показатель 2.50 интерпретируется как «низкое качество» — ответы в значительной мере не удовлетворяют пользовательские ожидания. Столь низкое значение является кумулятивным результатом проблем, выявленных на Tier 1 (низкая релевантность извлечённого контекста) и Tier 2 (низкая фактическая точность генерации).

#### 4.3.2. Анализ семантического сходства

Среднее семантическое сходство между сгенерированными и эталонными ответами составило **0.5382** при baseline 0.85 (отклонение -36.68%). Данный показатель отражает близость ответов по смыслу, а не по буквальному совпадению, и является более информативным, чем Exact Match Rate.

Значение 0.54 указывает на умеренную семантическую близость — ответы в целом направлены на одну тему с эталонами, однако содержат существенные смысловые расхождения. Это согласуется с выводами Tier 2 о низкой Answer Correctness.

#### 4.3.3. Анализ Response Semantic Consistency

Показатель семантической согласованности в Tier 3 составил **0.8705**, что незначительно превышает baseline 0.85 (+2.41%). Это положительный индикатор, свидетельствующий о стабильности работы системы при повторных запросах.

### 4.4. Выводы по Tier 3

Сквозное качество системы характеризуется как **критически низкое**:

1. **E2E Score 2.50** — на 40% ниже целевого значения;
2. **Semantic Similarity 0.54** — на 37% ниже baseline;
3. **Кумулятивный эффект проблем:** низкое качество является результатом совокупности проблем на всех уровнях системы.

Данные результаты указывают на необходимость комплексной оптимизации всей системы, а не отдельных компонентов.

---

## 5. Анализ качества эмбеддингов (Tier 0)

### 5.1. Методологический контекст

Tier 0 представляет собой анализ внутренних характеристик векторных представлений (embeddings), используемых в системе для семантического поиска. В отличие от последующих уровней, данный анализ не требует внешних меток и оценивает «врождённые» свойства векторного пространства: распределение расстояний, плотность, размерность и согласованность.

### 5.2. Результаты эмпирической оценки

**Таблица 4. Метрики качества эмбеддингов (Tier 0)**

| Метрика | Полученное значение |
|---------|---------------------|
| Total Samples | 202 |
| Avg Nearest Neighbor Distance | 0.4482 |
| Std Nearest Neighbor Distance | 0.1404 |
| Density Score | 2.2310 |
| Avg Spread | 0.8883 |
| Max Spread | 0.9710 |
| Spread Std | 0.0306 |
| Effective Dimensionality | 113 |
| Avg Pairwise Distance | 0.7940 |
| Std Pairwise Distance | 0.1197 |
| Min Pairwise Distance | 0.0000 |
| Max Pairwise Distance | 1.0994 |

### 5.3. Интерпретация результатов

#### 5.3.1. Анализ расстояний

Среднее расстояние до ближайшего соседа (Avg NN Distance) составило **0.4482** при стандартном отклонении 0.1404. Данное значение указывает на умеренную разреженность векторного пространства — документы в среднем находятся на среднем расстоянии друг от друга, без признаков избыточной кластеризации или чрезмерного разброса.

Среднее попарное расстояние (Avg Pairwise Distance) составило **0.7940**, что свидетельствует о хорошем общем распределении векторов в пространстве.

#### 5.3.2. Анализ плотности и размерности

Показатель Density Score **2.2310** указывает на умеренную плотность векторного пространства — не слишком разреженное и не слишком плотное. Эффективная размерность (Effective Dimensionality) составила **113**, что ниже исходной размерности модели эмбеддингов и указывает на наличие некоторой избыточности, типичной для реальных данных.

#### 5.3.3. Анализ Spread

Показатель Spread (распространение) характеризует охват векторного пространства. Среднее значение **0.8883** при максимуме **0.9710** свидетельствует о широком распределении векторов и хорошем охвате пространства признаков.

### 5.4. Выводы по Tier 0

Качество эмбеддингов оценивается как **удовлетворительное**:

1. Векторное пространство демонстрирует адекватную структуру с умеренной плотностью;
2. Эффективная размерность 113 указывает на информативное представление данных;
3. Проблемы Tier 1, вероятно, обусловлены не столько качеством эмбеддингов, сколько алгоритмом ранжирования или содержимым чанков.

---

## 6. Анализ утилизации базы знаний

### 6.1. Методологический контекст

Данный анализ направлен на оценку эффективности использования имеющейся базы знаний — какая доля чанков фактически используется при ответах на пользовательские запросы. Это важный показатель, позволяющий выявить «мертвые зоны» в базе знаний, которые никогда не извлекаются поисковой системой.

### 6.2. Результаты эмпирической оценки

**Таблица 5. Метрики утилизации базы знаний**

| Метрика | Полученное значение |
|---------|---------------------|
| Total Chunks | 202 |
| Used Chunks | 177 |
| Unused Chunks | 25 |
| Utilization Rate | 87.62% |
| Questions Source | real |
| Question Count | 251 |
| Top-k | 10 |

### 6.3. Интерпретация результатов

Коэффициент утилизации составил **87.62%** — 177 из 202 чанков были использованы при ответах на 251 реальный пользовательский запрос. Это свидетельствует о том, что **25 чанков (12.38%)** ни разу не были извлечены поисковой системой.

Наличие неиспользуемых чанков может указывать на: (а) избыточность информации в базе знаний, (б) неоптимальное разбиение на чанки, (в) низкое качество текстов невостребованных чанков. Рекомендуется провести аудит неиспользуемых чанков для выявления причин их невостребованности.

---

## 7. Анализ тематического покрытия

### 7.1. Методологический контекст

Анализ тематического покрытия направлен на оценку того, насколько полно база знаний охватывает различные тематические кластеры пользовательских запросов. Используется кластеризация методом k-means для выявления 20 основных тем в корпусе вопросов.

### 7.2. Результаты кластеризации

В результате кластеризации 251 вопроса выделено 20 тематических кластеров со следующим распределением:

**Таблица 6. Тематические кластеры пользовательских запросов**

| Topic ID | Question Count | Unique Chunks | Unique URLs | Representative Topics |
|----------|----------------|---------------|-------------|----------------------|
| 0 | 13 | 33 | 22 | Военкомат, общежитие |
| 1 | 14 | 24 | 12 | Перевод между направлениями |
| 2 | 17 | 11 | 9 | Физкультура, спортзал |
| 3 | 8 | 11 | 9 | Благодарности, не относящиеся |
| 4 | 20 | 20 | 19 | Пропуска, студенческие билеты |
| 5 | 14 | 40 | 27 | Общие вопросы об университете |
| 6 | 19 | 44 | 34 | Мероприятия, объединения |
| 7 | 13 | 32 | 26 | Справки об обучении |
| 8 | 10 | 40 | 25 | Учебный процесс |
| 9 | 11 | 16 | 13 | Стипендия, финансы |
| 10 | 14 | 29 | 25 | Расписание, стоимость |
| 11 | 6 | 18 | 16 | Элективы, выбор дисциплин |
| 12 | 13 | 21 | 18 | Физкультура |
| 13 | 12 | 25 | 11 | Академический отпуск |
| 14 | 13 | 23 | 22 | Навигация по корпусам |
| 15 | 11 | 30 | 21 | Общие вопросы, не по теме |
| 16 | 10 | 17 | 12 | Восстановление документов |
| 17 | 5 | 12 | 10 | Справки |
| 18 | 8 | 29 | 15 | Оплата обучения |
| 19 | 20 | 29 | 21 | Направления, специальности |

Среднее количество уникальных чанков на тему: **25.2**.

### 7.3. Интерпретация результатов

Анализ тематических кластеров выявляет следующие закономерности:

1. **Широкий охват тематик:** система способна отвечать на вопросы из различных предметных областей — от военкомата и общежитий до физкультуры и оплаты обучения;
2. **Неравномерность распределения:** наиболее представлены темы «Пропуска» (20 вопросов), «Мероприятия» (19), «Физкультура» (17);
3. **Наличие оффтопик-кластеров:** кластеры 3 (благодарности) и 15 (общие вопросы не по теме) указывают на необходимость улучшения обработки нерелевантных запросов;
4. **Сильное перекрытие по URL:** высокое соотношение unique_chunks к question_count указывает на хорошую диверсификацию источников.

---

## 8. Анализ предметной области реальных запросов

### 8.1. Методологический контекст

Данный раздел посвящён анализу корпуса реальных пользовательских запросов, накопленных в системе. Это позволяет оценить: (а) полноту охвата предметной области, (б) качество ответов на реальные запросы, (в) типичные паттерны использования системы.

### 8.2. Результаты эмпирической оценки

**Таблица 7. Метрики предметной области**

| Метрика | Полученное значение |
|---------|---------------------|
| Total Questions | 5,248 |
| With Answers | 3,039 (57.91%) |
| Without Answers | 2,209 (42.09%) |
| Scored Questions | 576 |
| Score Distribution | 5: 252, 4: 1, 1: 323 |
| Score 5 Questions | 252 |
| Score 1 Questions | 323 |
| Avg Question Length | 50.08 символов |

### 8.3. Интерпретация результатов

#### 8.3.1. Анализ охвата

Из 5,248 накопленных вопросов система дала ответы на 3,039 (57.91%). Это означает, что **42.09% запросов остались без ответа** — критически важный показатель, требующий внимания.

Показатель с оценками: 252 вопроса получили оценку «5» (отлично), 1 — оценку «4», 323 — оценку «1» (неудовлетворительно). Соотношение положительных и отрицательных оценок: **252:323** или приблизительно **0.78:1** — незначительное преобладание положительных оценок.

#### 8.3.2. Анализ лексики

Наиболее частотные токены в корпусе вопросов:

1. «как» — 1,137 вхождений (универсальный вопросительный маркер);
2. «можно» — 427 вхождений (запрос разрешения/возможности);
3. «что» — 418 вхождений (уточнение);
4. «если» — 356 вхождений (условные конструкции);
5. «для» — 347 вхождений;
6. «когда» — 309 вхождений;
7. «где» — 281 вхождений (локация);
8. «тюмгу» — 262 вхождений (контекстуальный маркер).

Среди сленговых маркеров зафиксированы: «препод» — 61, «сессия» — 28, «пересдача» — 19, «пара» — 11.

### 8.4. Выводы по предметной области

1. **Значительная доля безответных запросов:** 42.09% не получили ответа;
2. **Поляризованная оценка качества:** соотношение оценок 5:1 составляет 0.78:1;
3. **Типичные паттерны:** вопросы начинаются с «как», «можно», «что», «где», «когда»;
4. **Необходимость расширения базы знаний** для покрытия неотвеченных запросов.

---

## 9. Сводные выводы и рекомендации

### 9.1. Общая оценка состояния системы

Проведённое комплексное исследование позволяет сделать однозначный вывод о **критическом состоянии** системы «Вопрошалыч» по критериям, принятым в рамках данного бенчмаркинга. Все три ключевых уровня оценки (Tier 1, Tier 2, Tier 3) демонстрируют существенные отклонения от целевых baseline-значений:

- **Tier 1 (Retrieval):** MRR = 0.59 при baseline 0.80 (-25.69%);
- **Tier 2 (Generation):** Answer Correctness = 2.95 при baseline 4.20 (-29.65%);
- **Tier 3 (E2E):** E2E Score = 2.50 при baseline 4.20 (-40.42%).

Система в целом характеризуется как **требующая существенной оптимизации**.

### 9.2. Выявленные проблемы

#### 9.2.1. Проблемы retrieval-слоя

- Низкая пертинентность top-1 ранжирования (34.65%);
- Недостаточная конкурентоспособность относительно baseline по Hit Rate и MRR;
- Высокая полнота при низкой точности — избыток нерелевантных документов в результатах.

#### 9.2.2. Проблемы генеративного слоя

- Высокий уровень галлюцинаций (Faithfulness 3.44);
- Низкая фактическая точность (Answer Correctness 2.95);
- Значительное расхождение с эталонными ответами.

#### 9.2.3. Системные проблемы

- 42.09% реальных запросов остаются без ответа;
- Поляризованная оценка качества пользователями;
- Неравномерное тематическое покрытие.

### 9.3. Рекомендации по оптимизации

1. **Для retrieval-слоя:**
   - Внедрение гибридного поиска (векторный + BM25);
   - Оптимизация процедуры разбиения документов на чанки;
   - Калибровка параметров косинусного сходства;
   - Рассмотрение альтернативных моделей эмбеддингов.

2. **Для генеративного слоя:**
   - Оптимизация system prompt с акцентом на фактическую точность;
   - Калибровка параметра temperature;
   - Расширение контекстного окна;
   - Рассмотрение перехода на более производительную LLM.

3. **Для базы знаний:**
   - Аудит неиспользуемых чанков;
   - Расширение покрытия неотвеченных тем;
   - Оптимизация качества текстов существующих чанков.

4. **Для пользовательского опыта:**
   - Внедрение механизма эскалации неотвеченных запросов;
   - Улучшение обработки оффтопик-запросов;
   - Оптимизация для типичных паттернов («как», «можно», «где»).

---

## 10. Заключение

Проведённое исследование представляет собой комплексную оценку состояния системы «Вопрошалыч» на основе научно обоснованной методологии бенчмаркинга RAG-систем. Результаты свидетельствуют о наличии существенных проблем на всех уровнях архитектуры системы, требующих системного подхода к оптимизации.

Общий статус системы определён как **critical** — это указывает на необходимость приоритетного внимания к выявленным проблемам. Вместе с тем, положительные аспекты (стабильность работы, высокая семантическая согласованность, хорошие характеристики эмбеддингов) создают основу для успешной оптимизации при целенаправленной работе над выявленными недостатками.

Рекомендуется сформировать план мероприятий по устранению выявленных проблем с приоритизацией по критичности и ресурсоёмкости, а также организовать регулярный повторный бенчмаркинг для отслеживания динамики улучшений.

---

*Отчёт составлен на основе данных бенчмарка от 23 февраля 2026 года (Git-коммит 488332f)*
